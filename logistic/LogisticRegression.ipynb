{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJU3r9IhS/G1I9h7hzdfgD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeeep-prajapati/pytorch_Practice_Repo/blob/main/logistic/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8HUy6bqvUOxX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "9xmNDXhjUeO3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download = True)\n",
        "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "CBUfOVmlUxMq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('data count : ',len(train_dataset.train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWjfI_iMVhVY",
        "outputId": "44ebbddd-2ba5-408f-99c4-26b8605a229d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data count :  60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)"
      ],
      "metadata": {
        "id": "OzBqavx5VtVu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)"
      ],
      "metadata": {
        "id": "OLL3771oWAQZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(input_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n"
      ],
      "metadata": {
        "id": "rX4guLSmWSw8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1,28*28)\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOlCs99GW5ED",
        "outputId": "a7208a12-d2f2-4e0b-ed09-488f157ca625"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 1.1556\n",
            "Epoch [1/5], Step [200/600], Loss: 0.9526\n",
            "Epoch [1/5], Step [300/600], Loss: 0.8376\n",
            "Epoch [1/5], Step [400/600], Loss: 0.9471\n",
            "Epoch [1/5], Step [500/600], Loss: 0.8296\n",
            "Epoch [1/5], Step [600/600], Loss: 0.7831\n",
            "Epoch [2/5], Step [100/600], Loss: 0.8723\n",
            "Epoch [2/5], Step [200/600], Loss: 0.7933\n",
            "Epoch [2/5], Step [300/600], Loss: 0.9069\n",
            "Epoch [2/5], Step [400/600], Loss: 1.0115\n",
            "Epoch [2/5], Step [500/600], Loss: 0.8550\n",
            "Epoch [2/5], Step [600/600], Loss: 0.7478\n",
            "Epoch [3/5], Step [100/600], Loss: 0.8702\n",
            "Epoch [3/5], Step [200/600], Loss: 0.9090\n",
            "Epoch [3/5], Step [300/600], Loss: 0.8665\n",
            "Epoch [3/5], Step [400/600], Loss: 0.8546\n",
            "Epoch [3/5], Step [500/600], Loss: 0.7917\n",
            "Epoch [3/5], Step [600/600], Loss: 0.8676\n",
            "Epoch [4/5], Step [100/600], Loss: 0.7453\n",
            "Epoch [4/5], Step [200/600], Loss: 0.7325\n",
            "Epoch [4/5], Step [300/600], Loss: 0.8577\n",
            "Epoch [4/5], Step [400/600], Loss: 0.7907\n",
            "Epoch [4/5], Step [500/600], Loss: 0.7178\n",
            "Epoch [4/5], Step [600/600], Loss: 0.7323\n",
            "Epoch [5/5], Step [100/600], Loss: 0.7029\n",
            "Epoch [5/5], Step [200/600], Loss: 0.7950\n",
            "Epoch [5/5], Step [300/600], Loss: 0.8906\n",
            "Epoch [5/5], Step [400/600], Loss: 0.7268\n",
            "Epoch [5/5], Step [500/600], Loss: 0.7083\n",
            "Epoch [5/5], Step [600/600], Loss: 0.7105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet calculates the accuracy of a trained PyTorch neural network model on a test dataset. Here's a breakdown of each part:\n",
        "\n",
        "1. **`with torch.no_grad():`**:\n",
        "   - This context manager is used to temporarily disable gradient calculation in PyTorch. This is beneficial when you're evaluating the model's performance and don't need to compute gradients for any operations, saving memory and computation time.\n",
        "\n",
        "2. **Accuracy Calculation**:\n",
        "   - `correct = 0` and `total = 0`: These variables are initialized to keep track of the number of correctly predicted samples and the total number of samples in the test dataset, respectively.\n",
        "   \n",
        "3. **Looping Over Test Dataset**:\n",
        "   - `for images, labels in test_loader:`: This loop iterates over the batches of images and corresponding labels in the test dataset using `test_loader`.\n",
        "   - `images = images.reshape(-1, 28*28)`: The images are reshaped into a 2D tensor where each row represents a flattened image (28x28 pixels).\n",
        "   - `outputs = model(images)`: The model predicts outputs for the batch of images.\n",
        "   - `_, predicted = torch.max(outputs.data, 1)`: The `torch.max()` function is used to get the index of the maximum value along dimension 1 (which corresponds to the predicted class) for each sample in the batch. The actual predicted class labels are stored in the `predicted` tensor.\n",
        "   \n",
        "4. **Calculating Accuracy**:\n",
        "   - `total = total + labels.size(0)`: The total count of samples is incremented by the size of the current batch.\n",
        "   - `correct = correct + (predicted == labels).sum()`: This line calculates the number of correctly predicted samples by comparing the predicted labels (`predicted`) with the true labels (`labels`). `(predicted == labels)` creates a boolean tensor with `True` for correct predictions and `False` otherwise. `.sum()` is then used to count the number of `True` values.\n",
        "   \n",
        "5. **Printing Accuracy**:\n",
        "   - `print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))`: Finally, the accuracy of the model on the test dataset is printed as a percentage. The number of correct predictions (`correct`) is divided by the total number of samples (`total`), multiplied by 100 to convert it to a percentage.\n",
        "   "
      ],
      "metadata": {
        "id": "oEyvkiLAZ5v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images,labels in test_loader:\n",
        "    images = images.reshape(-1,28*28)\n",
        "    outputs = model(images)\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    total = total + labels.size(0)\n",
        "    correct = correct + (predicted == labels).sum()\n",
        "\n",
        "  print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0igfhgcX5Us",
        "outputId": "84d36bb1-e693-46a6-85d5-d51e2b9049dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 85.66999816894531 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7lygjhwZM2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
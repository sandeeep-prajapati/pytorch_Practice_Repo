{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqVwsoQcv1tsVO1bGSA/6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeeep-prajapati/pytorch_Practice_Repo/blob/main/feedForWardNeuralNetWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HykvBPdaU3-d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "gpExyloSVTtH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOhbM9NfVegx",
        "outputId": "d183c2ae-6ea0-44f7-ece2-b0a8ff4ab629"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                           train=True,\n",
        "                                           transform =transforms.ToTensor(),\n",
        "                                           download = True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "I2Z9O6BJVi_M",
        "outputId": "6465362b-a0d5-4f9d-f473-9806f80322b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 84523578.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31512927.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 23789166.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9963665.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torchvision.datasets' has no attribute 'MNST'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-966594a27162>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                            \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                            download = True)\n\u001b[0;32m----> 5\u001b[0;31m test_dataset = torchvision.datasets.MNST(root='./data',\n\u001b[0m\u001b[1;32m      6\u001b[0m                                          \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                          transform = transforms.ToTensor())\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap_dataset_for_transforms_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {__name__!r} has no attribute {name!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.datasets' has no attribute 'MNST'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                         train = True,\n",
        "                                         transform = transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = False)"
      ],
      "metadata": {
        "id": "qUXvgOMCZ1dv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "  def forward(self,x):\n",
        "    out= self.fc1(x)\n",
        "    out=self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "YpElRYnhZ_kr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cpu = NeuralNet(input_size, hidden_size, num_classes)\n",
        "print(list(model_cpu.children())[0].weight)\n",
        "model = model_cpu.to(device)\n",
        "print(list(model.children())[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDzWciQbP20",
        "outputId": "46963474-5ac5-40d6-a048-a5f7c67a86bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0131,  0.0085,  0.0169,  ...,  0.0258,  0.0249, -0.0286],\n",
            "        [ 0.0254, -0.0266,  0.0204,  ...,  0.0304,  0.0060, -0.0200],\n",
            "        [-0.0115, -0.0070, -0.0081,  ...,  0.0342,  0.0164, -0.0052],\n",
            "        ...,\n",
            "        [ 0.0104, -0.0075,  0.0342,  ...,  0.0167,  0.0200,  0.0109],\n",
            "        [ 0.0014,  0.0039,  0.0357,  ...,  0.0040, -0.0238, -0.0336],\n",
            "        [ 0.0195,  0.0095, -0.0042,  ...,  0.0314,  0.0279, -0.0318]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0131,  0.0085,  0.0169,  ...,  0.0258,  0.0249, -0.0286],\n",
            "        [ 0.0254, -0.0266,  0.0204,  ...,  0.0304,  0.0060, -0.0200],\n",
            "        [-0.0115, -0.0070, -0.0081,  ...,  0.0342,  0.0164, -0.0052],\n",
            "        ...,\n",
            "        [ 0.0104, -0.0075,  0.0342,  ...,  0.0167,  0.0200,  0.0109],\n",
            "        [ 0.0014,  0.0039,  0.0357,  ...,  0.0040, -0.0238, -0.0336],\n",
            "        [ 0.0195,  0.0095, -0.0042,  ...,  0.0314,  0.0279, -0.0318]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "kem6TsuUblJW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels)in enumerate(train_loader):\n",
        "    images = images.reshape(-1,28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    output = model(images)\n",
        "    loss = criterion(output,labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1) % (total_step/6) == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R3VUoJ8b7gk",
        "outputId": "9e46136c-190f-46ee-d719-2078275d3528"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.0155\n",
            "Epoch [1/5], Step [200/600], Loss: 0.0220\n",
            "Epoch [1/5], Step [300/600], Loss: 0.0290\n",
            "Epoch [1/5], Step [400/600], Loss: 0.0160\n",
            "Epoch [1/5], Step [500/600], Loss: 0.0216\n",
            "Epoch [1/5], Step [600/600], Loss: 0.1149\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0088\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0173\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0198\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0171\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0190\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0952\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0057\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0106\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0175\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0057\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0143\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0678\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0032\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0066\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0091\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0067\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0124\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0286\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0019\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0064\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0234\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0102\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0084\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  correct =0\n",
        "  total = 0\n",
        "  for images,labels in test_dataset:\n",
        "    images = images.reshape(-1,28*28).to(device)\n",
        "    output= model(images)\n",
        "    _,predicted = torch.max(output.data,1)\n",
        "    total += 1\n",
        "    correct+=(predicted == labels).sum().item()\n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgN0oJ7MdwTl",
        "outputId": "cf49009b-3e9e-4f0e-9ae5-c2eec002591a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 99.68 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "metadata": {
        "id": "qDqlx8BOfZWn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MbGc1c1hfyRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}